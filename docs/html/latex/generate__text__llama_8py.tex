\doxysection{/\+Users/onkars/\+Documents/\+Projects/\+LLM-\/\+Toxicity-\/\+Optimization/src/generation/text/generate\+\_\+text\+\_\+llama.py File Reference}
\hypertarget{generate__text__llama_8py}{}\label{generate__text__llama_8py}\index{/Users/onkars/Documents/Projects/LLM-\/Toxicity-\/Optimization/src/generation/text/generate\_text\_llama.py@{/Users/onkars/Documents/Projects/LLM-\/Toxicity-\/Optimization/src/generation/text/generate\_text\_llama.py}}
\doxysubsubsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
namespace \mbox{\hyperlink{namespacegenerate__text__llama}{generate\+\_\+text\+\_\+llama}}
\end{DoxyCompactItemize}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacegenerate__text__llama_afe1902e7f1bdd09fabfaaa697e3eea0a}{generate\+\_\+text\+\_\+llama.\+initialize\+\_\+model}} (model\+\_\+name="{}meta-\/llama/Llama-\/3.\+2-\/1B-\/instruct"{})
\item 
\mbox{\hyperlink{namespacegenerate__text__llama_ab82f127726c389dea84e8008f18abf5e}{generate\+\_\+text\+\_\+llama.\+clean\+\_\+response}} (response, prompt)
\item 
\mbox{\hyperlink{namespacegenerate__text__llama_a03aeb9c47f7200a693eb5cb7a08a634c}{generate\+\_\+text\+\_\+llama.\+generate\+\_\+text}} (prompt, tokenizer, model)
\item 
\mbox{\hyperlink{namespacegenerate__text__llama_a231106df14ebbce674979d744b4df624}{generate\+\_\+text\+\_\+llama.\+save\+\_\+response}} (prompt, response, output\+\_\+file\+\_\+path)
\item 
\mbox{\hyperlink{namespacegenerate__text__llama_acdd4ce62a805a2a409743e5dba0dd0cb}{generate\+\_\+text\+\_\+llama.\+main}} ()
\end{DoxyCompactItemize}
